{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "## 4. Metricas y Conclusiones\n",
    "\n",
    "En este notebook realizaremos una comparativa exhaustiva de los modelos entrenados en los notebooks anteriores:\n",
    "- **Machine Learning**: Logistic Regression y Naive Bayes\n",
    "- **Deep Learning**: GRU y LSTM con Word2Vec\n",
    "\n",
    "El objetivo es analizar el rendimiento de cada modelo en el contexto del analisis de sentimiento de reviews de productos de belleza, utilizando un dataset balanceado de aproximadamente 6000 reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "### 4.1 Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# Configuracion de visualizacion\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_results",
   "metadata": {},
   "source": [
    "### 4.2 Carga de Resultados\n",
    "\n",
    "Cargamos los resultados guardados de los modelos de Machine Learning y Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "load_ml_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados Deep Learning:\n",
      "             Model  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
      "0              GRU  0.512222   0.506329  0.977778  0.667172  0.511862\n",
      "1  LSTM + Word2Vec  0.627778   0.574194  0.988889  0.726531  0.634600\n",
      "\n",
      "Shape: (2, 6)\n"
     ]
    }
   ],
   "source": [
    "# Resultados de Deep Learning (guardados en CSV)\n",
    "df_dl = pd.read_csv('Outputs/results_deep_learning.csv')\n",
    "print(\"Resultados Deep Learning:\")\n",
    "print(df_dl)\n",
    "print(f\"\\nShape: {df_dl.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "create_ml_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados Machine Learning:\n",
      "                 Model  Accuracy  Precision  Recall  F1-Score  ROC-AUC\n",
      "0  Logistic Regression    0.8533      0.855  0.8533     0.853    0.925\n",
      "1          Naive Bayes    0.8200      0.818  0.8200     0.819    0.895\n"
     ]
    }
   ],
   "source": [
    "ml_results = {\n",
    "    'Model': ['Logistic Regression', 'Naive Bayes'],\n",
    "    'Accuracy': [0.8533, 0.8200],  # Valores aproximados del notebook 3a\n",
    "    'Precision': [0.8550, 0.8180],\n",
    "    'Recall': [0.8533, 0.8200],\n",
    "    'F1-Score': [0.8530, 0.8190],\n",
    "    'ROC-AUC': [0.9250, 0.8950]  # Valores aproximados\n",
    "}\n",
    "\n",
    "df_ml = pd.DataFrame(ml_results)\n",
    "print(\"Resultados Machine Learning:\")\n",
    "print(df_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "### 4.3 Comparativa General de Modelos\n",
    "\n",
    "Unimos los resultados de todos los modelos para realizar una comparativa completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "merge_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARATIVA COMPLETA DE MODELOS\n",
      "              Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC Tipo\n",
      "Logistic Regression  0.853300   0.855000 0.853300  0.853000 0.925000   ML\n",
      "        Naive Bayes  0.820000   0.818000 0.820000  0.819000 0.895000   ML\n",
      "                GRU  0.512222   0.506329 0.977778  0.667172 0.511862   DL\n",
      "    LSTM + Word2Vec  0.627778   0.574194 0.988889  0.726531 0.634600   DL\n"
     ]
    }
   ],
   "source": [
    "# Combinar resultados\n",
    "df_all = pd.concat([df_ml, df_dl], ignore_index=True)\n",
    "\n",
    "# Añadir columna de tipo de modelo\n",
    "df_all['Tipo'] = ['ML', 'ML', 'DL', 'DL']\n",
    "\n",
    "print(\"COMPARATIVA COMPLETA DE MODELOS\")\n",
    "print(df_all.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml_vs_dl_analysis",
   "metadata": {},
   "source": [
    "### 4.4 Analisis: Por que Machine Learning supera a Deep Learning\n",
    "\n",
    "En este estudio, los modelos de Machine Learning tradicional han superado significativamente a los modelos de Deep Learning (ML promedio: 83.7% vs DL promedio: 57%).\n",
    "\n",
    "#### 1. Causa probable: Tamaño del Dataset\n",
    "\n",
    "Nuestro dataset contiene aproximadamente 6,000 reviews balanceadas (4,198 entrenamiento + 1,400 test). Este tamaño es:\n",
    "- **Optimo para ML**: Los modelos tradicionales funcionan bien con miles de muestras\n",
    "- **Insuficiente para DL**: Las redes neuronales profundas tipicamente requieren +50,000 muestras para alcanzar su potencial\n",
    "\n",
    "**Relacion Parametros/Datos:**\n",
    "- **Logistic Regression**: Aproximadamente 10,000 parametros (vocabulario TF-IDF) / 4,198 muestras = 2.4 muestras por parametro\n",
    "- **LSTM/GRU**: Aproximadamente 100,000+ parametros / 4,198 muestras = 0.04 muestras por parametro\n",
    "\n",
    "Esta relacion desfavorable en DL conduce a:\n",
    "- Sobreajuste (overfitting)\n",
    "- Incapacidad para generalizar patrones complejos\n",
    "- Convergencia a soluciones suboptimas\n",
    "\n",
    "#### 2. Naturaleza del Problema: Analisis de Sentimiento\n",
    "\n",
    "El analisis de sentimiento en reviews es un problema relativamente lineal:\n",
    "- Palabras clave tienen fuerte correlacion con sentimiento (\"excelente\", \"horrible\", \"recomiendo\")\n",
    "- La presencia/ausencia de terminos especificos es altamente predictiva\n",
    "- No requiere comprension profunda de contexto o ironia en la mayoria de casos\n",
    "\n",
    "**TF-IDF captura efectivamente:**\n",
    "- Palabras discriminativas del dominio\n",
    "- Frecuencia relativa de terminos positivos/negativos\n",
    "- Bigramas relevantes\n",
    "\n",
    "#### 3. Problemas Especificos de los Modelos DL\n",
    "\n",
    "**GRU (Accuracy: 51%)**\n",
    "- Embeddings congelados no adaptados al dominio\n",
    "\n",
    "**LSTM (Accuracy: 63%)**\n",
    "- Sobreajuste evidente: Recall 98% pero Precision 57%\n",
    "- Predice demasiados falsos positivos\n",
    "- Aprende ruido en lugar de patrones generalizables\n",
    "- Embeddings Word2Vec genericos, no especializados en reviews de belleza\n",
    "\n",
    "#### 4. Ventajas de TF-IDF en este Contexto\n",
    "\n",
    "- **Representacion dispersa**: Captura vocabulario especifico del dominio\n",
    "- **Ponderacion inteligente**: Palabras frecuentes pero poco informativas reciben menor peso\n",
    "- **Bigramas**: Captura expresiones compuestas (\"muy bueno\", \"poco efectivo\")\n",
    "\n",
    "\n",
    "#### Prediccion: Que pasaria con mas datos\n",
    "\n",
    "Con un dataset de 50,000+ reviews **DL superaria a ML**: Con suficientes datos, las redes neuronales capturarian patrones mas sutiles\n",
    "\n",
    "Sin embargo, para este estudio con 6K muestras, ML es claramente superior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "### 4.5 Conclusiones Finales\n",
    "\n",
    "#### Contexto del Estudio\n",
    "Este analisis se ha realizado sobre un dataset balanceado de aproximadamente 6000 reviews de productos de belleza, con el objetivo de clasificar el sentimiento (positivo/negativo) de las opiniones de los usuarios.\n",
    "\n",
    "Los modelos de Machine Learning tradicional, especificamente Logistic Regression, han demostrado ser la opcion mas efectiva por accuracy. Los modelos de Deep Learning, requieren datasets mas grandes para demostrar su verdadero potencial en tareas de procesamiento de lenguaje natural."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP DL (Python 3.11)",
   "language": "python",
   "name": "nlp-dl-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
