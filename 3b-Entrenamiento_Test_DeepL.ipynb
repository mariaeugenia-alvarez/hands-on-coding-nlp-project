{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "## 3b. Entrenamiento modelo Deep Learning\n",
    "\n",
    "En este notebook implementaremos y compararemos dos modelos de Deep Learning:\n",
    "1. **GRU**: Versión eficiente de LSTM con menos parámetros, más rápido, bien para dataset pequeños\n",
    "2. **LSTM con Word2Vec**: Modelo estándar con embeddings pre-entrenados para capturar relacion semantica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c03dc7",
   "metadata": {},
   "source": [
    "### 3.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, GRU, Dense, Dropout, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Usar keras_preprocessing (compatible con Keras 3)\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_section",
   "metadata": {},
   "source": [
    "### 3.2 Carga de Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 5,995 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_processed_DL</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sculpting crean use this product and find that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keep your money foe the price one expects more...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fell apart after year was good while lasted bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>five stars works beautifully great for clients...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worst product recently purchased this product ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review_processed_DL  label_sentiment\n",
       "0  sculpting crean use this product and find that...                0\n",
       "1  keep your money foe the price one expects more...                1\n",
       "2  fell apart after year was good while lasted bu...                1\n",
       "3  five stars works beautifully great for clients...                0\n",
       "4  worst product recently purchased this product ...                1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos preprocesados del Notebook 2\n",
    "df = pd.read_pickle('Outputs/data/df_beauty_preprocessed_DL.pkl')\n",
    "\n",
    "print(f\"Dataset cargado: {len(df):,} reviews\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 5,995\n",
      "1    3000\n",
      "0    2995\n",
      "dtype: int64\n",
      "\n",
      "Ejemplo de texto preprocesado:\n",
      "sculpting crean use this product and find that when run out notice the difference the tautness skin especially around mouth and neck\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos \n",
    "X = df['review_processed_DL'].values\n",
    "y = df['label_sentiment'].values\n",
    "\n",
    "print(f\"Total: {len(X):,}\")\n",
    "print(pd.Series(y).value_counts())\n",
    "print(f\"\\nEjemplo de texto preprocesado:\")\n",
    "print(X[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenization_section",
   "metadata": {},
   "source": [
    "### 3.3 Tokenización\n",
    "\n",
    "Parámetros usados:\n",
    "- **vocab_size = 5000**: Balance entre cobertura y eficiencia para evitar overfitting\n",
    "- **max_length = 100**: Longitud promedio de reviews\n",
    "- **embedding_dim = 128**: Dimensión para Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tokenization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario total: 10,734 palabras únicas\n",
      "Vocabulario usado: 5,000 palabras\n",
      "Forma de X_padded: (5995, 100)\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 5000  \n",
    "MAX_LENGTH = 100   \n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# Tokenizer de Keras\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Convertir textos a secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding: todas las secuencias con misma longitud\n",
    "X_padded = pad_sequences(sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Vocabulario total: {len(tokenizer.word_index):,} palabras únicas\")\n",
    "print(f\"Vocabulario usado: {VOCAB_SIZE:,} palabras\")\n",
    "print(f\"Forma de X_padded: {X_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd7cc136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: sculpting crean use this product and find that when run out notice the difference the tautness skin ...\n",
      "Secuencia: [3264, 1, 22, 4, 10, 3, 199, 11, 36, 674, 29, 861, 2, 366, 2, 1, 43, 378, 188, 690]...\n",
      "Padded: [3264    1   22    4   10    3  199   11   36  674   29  861    2  366\n",
      "    2    1   43  378  188  690]...\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo:\n",
    "print(f\"Original: {X[0][:100]}...\")\n",
    "print(f\"Secuencia: {sequences[0][:20]}...\")\n",
    "print(f\"Padded: {X_padded[0][:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_section",
   "metadata": {},
   "source": [
    "### 3.4 División Train/Validation/Test\n",
    "\n",
    "con stratify para asegurar balanceo de clases en las divisiones\n",
    "\n",
    "- **Train**: 70% para entrenamiento\n",
    "- **Validation**: 15% para ajuste de hiperparámetros y early stopping\n",
    "- **Test**: 15% para evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4,198\n",
      "Validation: 897\n",
      "Test: 900 \n",
      "Train: Positivos=2097, Negativos=2101\n",
      "Positivos=448, Negativos=449\n",
      "Positivos=450, Negativos=450\n"
     ]
    }
   ],
   "source": [
    "# Train+Val (85%), Test (15%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_padded, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Train (70%), Val (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=RANDOM_STATE, stratify=y_temp  \n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Train: {len(X_train):,}\")\n",
    "print(f\"Validation: {len(X_val):,}\")\n",
    "print(f\"Test: {len(X_test):,} \")\n",
    "\n",
    "print(f\"Train: Positivos={np.sum(y_train==0)}, Negativos={np.sum(y_train==1)}\")\n",
    "print(f\"Positivos={np.sum(y_val==0)}, Negativos={np.sum(y_val==1)}\")\n",
    "print(f\"Positivos={np.sum(y_test==0)}, Negativos={np.sum(y_test==1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "word2vec_section",
   "metadata": {},
   "source": [
    "### 3.5 Entrenamiento de Word2Vec\n",
    "\n",
    "Word2Vec aprende representaciones semánticas, preentrenamos los embeddings antes de la LSTM\n",
    "\n",
    "**Parámetros:**\n",
    "- **vector_size=128**: Dimensión (coincide con EMBEDDING_DIM)\n",
    "- **window=5**: Contexto de palabras vecinas\n",
    "- **min_count=2**: Palabras que aparecen ≥2 veces\n",
    "- **sg=1**: Skip-gram (mejor para datasets pequeños)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "word2vec_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo delista: ['sculpting', 'crean', 'use', 'this', 'product', 'and', 'find', 'that', 'when', 'run', 'out', 'notice', 'the', 'difference', 'the']...\n",
      "Vocabulario Word2Vec: 5,544 palabras\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para Word2Vec convirtiendo a lista de palabras\n",
    "sentences = [text.split() for text in X] \n",
    "\n",
    "print(f\"Ejemplo delista: {sentences[0][:15]}...\")\n",
    "\n",
    "# Entrenar Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=EMBEDDING_DIM,  \n",
    "    window=5,                    \n",
    "    min_count=2,                \n",
    "    workers=4,                   \n",
    "    sg=1,                        \n",
    "    epochs=10,                   \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Vocabulario Word2Vec: {len(w2v_model.wv):,} palabras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7eb759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Word2Vec guardado en Outputs/models/word2vec_beauty.model\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo Word2Vec\n",
    "os.makedirs('Outputs/models', exist_ok=True)\n",
    "w2v_model.save('Outputs/models/word2vec_beauty.model')\n",
    "print(\"Modelo Word2Vec guardado en Outputs/models/word2vec_beauty.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "word2vec_explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'bad' es similar a:\n",
      "  - burnt: 0.709\n",
      "  - news: 0.707\n",
      "  - batch: 0.697\n",
      "  - horrible: 0.693\n",
      "  - nappy: 0.678\n",
      "\n",
      "'love' es similar a:\n",
      "  - amazing: 0.723\n",
      "  - fantastic: 0.719\n",
      "  - starter: 0.706\n",
      "  - awesome: 0.701\n",
      "  - loves: 0.693\n",
      "\n",
      "'hate' es similar a:\n",
      "  - besides: 0.878\n",
      "  - advertise: 0.868\n",
      "  - mesh: 0.866\n",
      "  - detail: 0.865\n",
      "  - technician: 0.863\n",
      "\n",
      "'price' es similar a:\n",
      "  - reasonable: 0.797\n",
      "  - deal: 0.785\n",
      "  - quantity: 0.752\n",
      "  - value: 0.749\n",
      "  - costume: 0.741\n",
      "\n",
      "'product' es similar a:\n",
      "  - satisfied: 0.704\n",
      "  - item: 0.682\n",
      "  - beyond: 0.678\n",
      "  - expectations: 0.678\n",
      "  - discount: 0.675\n",
      "\n",
      "'recommend' es similar a:\n",
      "  - anyone: 0.704\n",
      "  - reccomend: 0.675\n",
      "  - def: 0.657\n",
      "  - proof: 0.655\n",
      "  - yada: 0.651\n"
     ]
    }
   ],
   "source": [
    "# Explorar similitudes \n",
    "# Palabras de ejemplo relacionadas con sentiment\n",
    "test_words = ['bad', 'love', 'hate', 'price', 'product', 'recommend']\n",
    "\n",
    "for word in test_words:\n",
    "    if word in w2v_model.wv:\n",
    "        similar = w2v_model.wv.most_similar(word, topn=5)\n",
    "        print(f\"\\n'{word}' es similar a:\")\n",
    "        for sim_word, score in similar:\n",
    "            print(f\"  - {sim_word}: {score:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n'{word}' no está en el vocabulario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "embedding_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de embeddings creada: (5000, 128)\n",
      "Palabras encontradas en Word2Vec: 4,998/5,000 (100.0%)\n",
      "Palabras sin embedding (inicializadas a cero): 2\n"
     ]
    }
   ],
   "source": [
    "# Crear matriz de embeddings \n",
    "# Inicializar con ceros\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# Llenar matriz con vectores de Word2Vec\n",
    "words_found = 0\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if idx < VOCAB_SIZE:  # Solo palabras en nuestro vocabulario\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[idx] = w2v_model.wv[word]\n",
    "            words_found += 1\n",
    "\n",
    "coverage = (words_found / VOCAB_SIZE) * 100\n",
    "print(f\"Matriz de embeddings creada: {embedding_matrix.shape}\")\n",
    "print(f\"Palabras encontradas en Word2Vec: {words_found:,}/{VOCAB_SIZE:,} ({coverage:.1f}%)\")\n",
    "print(f\"Palabras sin embedding (inicializadas a cero): {VOCAB_SIZE - words_found:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gru_section",
   "metadata": {},
   "source": [
    "### 3.6 Modelo 1: GRU\n",
    "\n",
    "**Parámetros:**\n",
    "- **GRU units=64**: Balance entre capacidad y overfitting para ~5K samples\n",
    "- **Dropout=0.5**: Regularización fuerte para evitar overfitting\n",
    "- **trainable=False**: Mantener embeddings Word2Vec fijos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gru_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo GRU creado con embeddings de Word2Vec\n"
     ]
    }
   ],
   "source": [
    "def build_gru_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "            Embedding(VOCAB_SIZE, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LENGTH,trainable=False),\n",
    "        GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = build_gru_model(embedding_matrix)\n",
    "\n",
    "print(\"Modelo GRU creado con embeddings de Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33cc2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gru_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54e1b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks para GRU\n",
    "gru_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'outputs/models/gru_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "gru_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4733 - loss: 0.6942 - precision_3: 0.4297 - recall_3: 0.1971\n",
      "Epoch 1: val_accuracy improved from None to 0.51171, saving model to outputs/models/gru_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.4909 - loss: 0.6937 - precision_3: 0.4888 - recall_3: 0.3746 - val_accuracy: 0.5117 - val_loss: 0.6920 - val_precision_3: 0.5063 - val_recall_3: 0.9822\n",
      "Epoch 2/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5096 - loss: 0.6916 - precision_3: 0.5073 - recall_3: 0.9013\n",
      "Epoch 2: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5033 - loss: 0.6914 - precision_3: 0.5026 - recall_3: 0.7477 - val_accuracy: 0.4994 - val_loss: 0.6916 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4982 - loss: 0.6909 - precision_3: 0.4960 - recall_3: 0.5917\n",
      "Epoch 3: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.4981 - loss: 0.6916 - precision_3: 0.4988 - recall_3: 0.5750 - val_accuracy: 0.5072 - val_loss: 0.6917 - val_precision_3: 0.5040 - val_recall_3: 0.9755\n",
      "Epoch 4/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5114 - loss: 0.6898 - precision_3: 0.5158 - recall_3: 0.8646\n",
      "Epoch 4: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5124 - loss: 0.6906 - precision_3: 0.5091 - recall_3: 0.7158 - val_accuracy: 0.5006 - val_loss: 0.6919 - val_precision_3: 0.6667 - val_recall_3: 0.0045\n",
      "Epoch 5/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5010 - loss: 0.6904 - precision_3: 0.4967 - recall_3: 0.2311\n",
      "Epoch 5: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5007 - loss: 0.6900 - precision_3: 0.5012 - recall_3: 0.5112 - val_accuracy: 0.4994 - val_loss: 0.6917 - val_precision_3: 0.5000 - val_recall_3: 0.0067\n",
      "Epoch 6/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5112 - loss: 0.6892 - precision_3: 0.5206 - recall_3: 0.3110\n",
      "Epoch 6: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5121 - loss: 0.6880 - precision_3: 0.5133 - recall_3: 0.4860 - val_accuracy: 0.5050 - val_loss: 0.6956 - val_precision_3: 0.5029 - val_recall_3: 0.9666\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5212 - loss: 0.6884 - precision_3: 0.5185 - recall_3: 0.7276\n",
      "Epoch 7: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5124 - loss: 0.6877 - precision_3: 0.5095 - recall_3: 0.6906 - val_accuracy: 0.5028 - val_loss: 0.6926 - val_precision_3: 0.6667 - val_recall_3: 0.0134\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Entrenamiento GRU completado\n"
     ]
    }
   ],
   "source": [
    "# Entrenar GRU\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "gru_history = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=gru_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Entrenamiento GRU completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm_section",
   "metadata": {},
   "source": [
    "### 3.7 Modelo 2: LSTM con Word2Vec\n",
    "\n",
    "**Ventajas de LSTM:**\n",
    "- **Más parámetros**: Mayor capacidad de aprendizaje\n",
    "- **Mejor para secuencias largas**: Captura dependencias complejas\n",
    "- **Maneja negaciones**: Mejor contexto para sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "lstm_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo LSTM creado con embeddings de Word2Vec\n"
     ]
    }
   ],
   "source": [
    "# Construir modelo LSTM con Word2Vec embeddings\n",
    "def build_lstm_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, EMBEDDING_DIM,weights=[embedding_matrix],input_length=MAX_LENGTH,trainable=False),\n",
    "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_model = build_lstm_model(embedding_matrix)\n",
    "\n",
    "print(\"Modelo LSTM creado con embeddings de Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed67c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22dbc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks para LSTM\n",
    "lstm_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'outputs/models/lstm_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "lstm_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4841 - loss: 0.6935 - precision_4: 0.4752 - recall_4: 0.4028\n",
      "Epoch 1: val_accuracy improved from None to 0.50613, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.4900 - loss: 0.6928 - precision_4: 0.4883 - recall_4: 0.3974 - val_accuracy: 0.5061 - val_loss: 0.6918 - val_precision_4: 0.5035 - val_recall_4: 0.9666\n",
      "Epoch 2/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5059 - loss: 0.6923 - precision_4: 0.4986 - recall_4: 0.6199\n",
      "Epoch 2: val_accuracy improved from 0.50613 to 0.50948, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5138 - loss: 0.6915 - precision_4: 0.5109 - recall_4: 0.6687 - val_accuracy: 0.5095 - val_loss: 0.6915 - val_precision_4: 0.5052 - val_recall_4: 0.9755\n",
      "Epoch 3/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5091 - loss: 0.6897 - precision_4: 0.5076 - recall_4: 0.7669\n",
      "Epoch 3: val_accuracy improved from 0.50948 to 0.51171, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5040 - loss: 0.6894 - precision_4: 0.5036 - recall_4: 0.6378 - val_accuracy: 0.5117 - val_loss: 0.6919 - val_precision_4: 0.5064 - val_recall_4: 0.9755\n",
      "Epoch 4/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5051 - loss: 0.6883 - precision_4: 0.4959 - recall_4: 0.5440\n",
      "Epoch 4: val_accuracy did not improve from 0.51171\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5095 - loss: 0.6891 - precision_4: 0.5105 - recall_4: 0.4879 - val_accuracy: 0.5095 - val_loss: 0.6925 - val_precision_4: 0.5052 - val_recall_4: 0.9777\n",
      "Epoch 5/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5221 - loss: 0.6872 - precision_4: 0.5176 - recall_4: 0.9380\n",
      "Epoch 5: val_accuracy improved from 0.51171 to 0.52731, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5126 - loss: 0.6862 - precision_4: 0.5091 - recall_4: 0.7292 - val_accuracy: 0.5273 - val_loss: 0.6935 - val_precision_4: 0.5152 - val_recall_4: 0.9443\n",
      "Epoch 6/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6179 - loss: 0.6319 - precision_4: 0.5701 - recall_4: 0.9044\n",
      "Epoch 6: val_accuracy improved from 0.52731 to 0.63322, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6255 - loss: 0.6229 - precision_4: 0.5773 - recall_4: 0.9405 - val_accuracy: 0.6332 - val_loss: 0.6035 - val_precision_4: 0.5783 - val_recall_4: 0.9866\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5971 - loss: 0.6423 - precision_4: 0.5602 - recall_4: 0.9617\n",
      "Epoch 7: val_accuracy did not improve from 0.63322\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5586 - loss: 0.6596 - precision_4: 0.5330 - recall_4: 0.9524 - val_accuracy: 0.5373 - val_loss: 0.6730 - val_precision_4: 0.5201 - val_recall_4: 0.9800\n",
      "Epoch 8/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5501 - loss: 0.6624 - precision_4: 0.5274 - recall_4: 0.9426\n",
      "Epoch 8: val_accuracy did not improve from 0.63322\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5696 - loss: 0.6503 - precision_4: 0.5398 - recall_4: 0.9495 - val_accuracy: 0.5909 - val_loss: 0.6353 - val_precision_4: 0.5516 - val_recall_4: 0.9755\n",
      "Epoch 9/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5782 - loss: 0.6548 - precision_4: 0.5433 - recall_4: 0.9661\n",
      "Epoch 9: val_accuracy did not improve from 0.63322\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.5669 - loss: 0.6579 - precision_4: 0.5372 - recall_4: 0.9729 - val_accuracy: 0.5518 - val_loss: 0.6638 - val_precision_4: 0.5282 - val_recall_4: 0.9800\n",
      "Epoch 10/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5793 - loss: 0.6610 - precision_4: 0.5490 - recall_4: 0.9497\n",
      "Epoch 10: val_accuracy did not improve from 0.63322\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5557 - loss: 0.6849 - precision_4: 0.5376 - recall_4: 0.8030 - val_accuracy: 0.4983 - val_loss: 0.6919 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 11/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4922 - loss: 0.6948 - precision_4: 0.4827 - recall_4: 0.5150\n",
      "Epoch 11: val_accuracy did not improve from 0.63322\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.5074 - loss: 0.6931 - precision_4: 0.5071 - recall_4: 0.5645 - val_accuracy: 0.5006 - val_loss: 0.6913 - val_precision_4: 0.6667 - val_recall_4: 0.0045\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Entrenamiento LSTM completado\n"
     ]
    }
   ],
   "source": [
    "# Entrenar LSTM\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=lstm_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Entrenamiento LSTM completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "### 3.8 Evaluación de Modelos en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "gru_eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Accuracy:  0.5000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1-Score:  0.0000\n",
      "ROC-AUC:   0.5093\n",
      "\n",
      "Classification Report GRU:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.50      1.00      0.67       450\n",
      "    Negative       0.00      0.00      0.00       450\n",
      "\n",
      "    accuracy                           0.50       900\n",
      "   macro avg       0.25      0.50      0.33       900\n",
      "weighted avg       0.25      0.50      0.33       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación GRU\n",
    "# Predicciones\n",
    "y_pred_gru_proba = gru_model.predict(X_test)\n",
    "y_pred_gru = (y_pred_gru_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Métricas\n",
    "gru_accuracy = accuracy_score(y_test, y_pred_gru)\n",
    "gru_precision = precision_score(y_test, y_pred_gru)\n",
    "gru_recall = recall_score(y_test, y_pred_gru)\n",
    "gru_f1 = f1_score(y_test, y_pred_gru)\n",
    "gru_auc = roc_auc_score(y_test, y_pred_gru_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {gru_accuracy:.4f}\")\n",
    "print(f\"Precision: {gru_precision:.4f}\")\n",
    "print(f\"Recall:    {gru_recall:.4f}\")\n",
    "print(f\"F1-Score:  {gru_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {gru_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report GRU:\")\n",
    "print(classification_report(y_test, y_pred_gru, target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "lstm_eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\n",
      "Accuracy:  0.6278\n",
      "Precision: 0.5742\n",
      "Recall:    0.9889\n",
      "F1-Score:  0.7265\n",
      "ROC-AUC:   0.6346\n",
      "\n",
      "Classification Report LSTM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.96      0.27      0.42       450\n",
      "    Negative       0.57      0.99      0.73       450\n",
      "\n",
      "    accuracy                           0.63       900\n",
      "   macro avg       0.77      0.63      0.57       900\n",
      "weighted avg       0.77      0.63      0.57       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación LSTM\n",
    "# Predicciones\n",
    "y_pred_lstm_proba = lstm_model.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Métricas\n",
    "lstm_accuracy = accuracy_score(y_test, y_pred_lstm)\n",
    "lstm_precision = precision_score(y_test, y_pred_lstm)\n",
    "lstm_recall = recall_score(y_test, y_pred_lstm)\n",
    "lstm_f1 = f1_score(y_test, y_pred_lstm)\n",
    "lstm_auc = roc_auc_score(y_test, y_pred_lstm_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {lstm_accuracy:.4f}\")\n",
    "print(f\"Precision: {lstm_precision:.4f}\")\n",
    "print(f\"Recall:    {lstm_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lstm_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {lstm_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report LSTM:\")\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "### 3.9 Comparación Final: GRU vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "comparison_table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACIÓN GRU vs LSTM + Word2Vec\n",
      "          Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "            GRU  0.500000   0.000000 0.000000  0.000000 0.509277\n",
      "LSTM + Word2Vec  0.627778   0.574194 0.988889  0.726531 0.634600\n",
      "\n",
      "Mejor modelo: LSTM + Word2Vec (F1-Score: 0.7265)\n",
      "Resultados guardados en outputs/results_deep_learning.csv\n"
     ]
    }
   ],
   "source": [
    "# Tabla comparativa\n",
    "results_dl = pd.DataFrame({\n",
    "    'Model': ['GRU', 'LSTM + Word2Vec'],\n",
    "    'Accuracy': [gru_accuracy, lstm_accuracy],\n",
    "    'Precision': [gru_precision, lstm_precision],\n",
    "    'Recall': [gru_recall, lstm_recall],\n",
    "    'F1-Score': [gru_f1, lstm_f1],\n",
    "    'ROC-AUC': [gru_auc, lstm_auc]\n",
    "})\n",
    "\n",
    "print(\"COMPARACIÓN GRU vs LSTM + Word2Vec\")\n",
    "print(results_dl.to_string(index=False))\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_idx = results_dl['F1-Score'].idxmax()\n",
    "best_model_name = results_dl.loc[best_model_idx, 'Model']\n",
    "best_f1 = results_dl.loc[best_model_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\nMejor modelo: {best_model_name} (F1-Score: {best_f1:.4f})\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_dl.to_csv('outputs/results_deep_learning.csv', index=False)\n",
    "print(\"Resultados guardados en outputs/results_deep_learning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions_section",
   "metadata": {},
   "source": [
    "### 3.10 Conclusiones\n",
    "\n",
    "#### Sobre Word2Vec:\n",
    "- **Ventajas**: Captura relaciones semánticas, palabras similares tienen vectores cercanos\n",
    "- **Limitaciones**: Requiere corpus grande, palabras OOV se inicializan a cero\n",
    "\n",
    "#### Comparación GRU vs LSTM:\n",
    "- **GRU**: Más eficiente, menos parámetros, entrena más rápido, menos overfitting\n",
    "- **LSTM**: Más parámetros, mejor para secuencias largas, estándar de la industria\n",
    "\n",
    "#### Recomendaciones:\n",
    "1. **Para datasets pequeños-medianos (~6K)**: GRU suele ser mejor opción\n",
    "2. **Para reviews largas**: LSTM captura mejor las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "save_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Mejor modelo (LSTM) guardado en Outputs/models/best_dl_model.h5\n",
      "✓ Tokenizer guardado en Outputs/models/tokenizer.pkl\n",
      "✓ Embedding matrix guardada en Outputs/models/embedding_matrix.npy\n",
      "Mejor modelo: LSTM + Word2Vec (F1-Score: 0.7265)\n"
     ]
    }
   ],
   "source": [
    "# Guardar el mejor modelo según F1-Score\n",
    "if best_model_name == 'GRU':\n",
    "    gru_model.save('Outputs/models/best_dl_model.h5')\n",
    "    print(f\"✓ Mejor modelo (GRU) guardado en Outputs/models/best_dl_model.h5\")\n",
    "else:\n",
    "    lstm_model.save('Outputs/models/best_dl_model.h5')\n",
    "    print(f\"✓ Mejor modelo (LSTM) guardado en Outputs/models/best_dl_model.h5\")\n",
    "\n",
    "# Guardar tokenizer\n",
    "with open('Outputs/models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"✓ Tokenizer guardado en Outputs/models/tokenizer.pkl\")\n",
    "\n",
    "# Guardar embedding matrix\n",
    "np.save('Outputs/models/embedding_matrix.npy', embedding_matrix)\n",
    "print(\"✓ Embedding matrix guardada en Outputs/models/embedding_matrix.npy\")\n",
    "\n",
    "print(f\"Mejor modelo: {best_model_name} (F1-Score: {best_f1:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP DL (Python 3.11)",
   "language": "python",
   "name": "nlp-dl-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
