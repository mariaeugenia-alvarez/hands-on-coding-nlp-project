{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "## 3b. Entrenamiento modelo Deep Learning\n",
    "\n",
    "En este notebook implementaremos y compararemos dos modelos de Deep Learning:\n",
    "1. **GRU**: Versión eficiente de LSTM con menos parámetros, más rápido, bien para dataset pequeños\n",
    "2. **LSTM con Word2Vec**: Modelo estándar con embeddings pre-entrenados para capturar relacion semantica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c03dc7",
   "metadata": {},
   "source": [
    "### 3.1 Carga de datos y setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, GRU, Dense, Dropout, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Usar keras_preprocessing (compatible con Keras 3)\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_section",
   "metadata": {},
   "source": [
    "### 3.2 Carga de Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 5,995 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_processed_DL</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sculpting crean use this product and find that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keep your money foe the price one expects more...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fell apart after year was good while lasted bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>five stars works beautifully great for clients...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worst product recently purchased this product ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review_processed_DL  label_sentiment\n",
       "0  sculpting crean use this product and find that...                0\n",
       "1  keep your money foe the price one expects more...                1\n",
       "2  fell apart after year was good while lasted bu...                1\n",
       "3  five stars works beautifully great for clients...                0\n",
       "4  worst product recently purchased this product ...                1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos preprocesados del Notebook 2\n",
    "df = pd.read_pickle('Outputs/data/df_beauty_preprocessed_DL.pkl')\n",
    "\n",
    "print(f\"Dataset cargado: {len(df):,} reviews\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de reviews: 5,995\n",
      "\n",
      "Distribución de sentimiento:\n",
      "1    3000\n",
      "0    2995\n",
      "dtype: int64\n",
      "\n",
      "Ejemplo de texto preprocesado:\n",
      "sculpting crean use this product and find that when run out notice the difference the tautness skin especially around mouth and neck\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para Deep Learning\n",
    "X = df['review_processed_DL'].values\n",
    "y = df['label_sentiment'].values\n",
    "\n",
    "print(f\"Total de reviews: {len(X):,}\")\n",
    "print(f\"\\nDistribución de sentimiento:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "print(f\"\\nEjemplo de texto preprocesado:\")\n",
    "print(X[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenization_section",
   "metadata": {},
   "source": [
    "### 3.3 Tokenización y Preparación de Secuencias\n",
    "\n",
    "**Parámetros justificados para dataset de belleza (~6K reviews):**\n",
    "- **vocab_size = 5000**: Balance entre cobertura y eficiencia\n",
    "- **max_length = 100**: Longitud promedio de reviews de productos\n",
    "- **embedding_dim = 128**: Dimensión estándar para Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tokenization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario total: 10,734 palabras únicas\n",
      "Vocabulario usado: 5,000 palabras\n",
      "Forma de X_padded: (5995, 100)\n",
      "\n",
      "Ejemplo de transformación:\n",
      "Original: sculpting crean use this product and find that when run out notice the difference the tautness skin ...\n",
      "Secuencia: [3264, 1, 22, 4, 10, 3, 199, 11, 36, 674, 29, 861, 2, 366, 2, 1, 43, 378, 188, 690]...\n",
      "Padded: [3264    1   22    4   10    3  199   11   36  674   29  861    2  366\n",
      "    2    1   43  378  188  690]...\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de tokenización\n",
    "VOCAB_SIZE = 5000  # Vocabulario limitado para evitar overfitting\n",
    "MAX_LENGTH = 100   # Longitud máxima de secuencia\n",
    "EMBEDDING_DIM = 128  # Dimensión de embeddings (debe coincidir con Word2Vec)\n",
    "\n",
    "# Tokenizer de Keras\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Convertir textos a secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding: todas las secuencias deben tener la misma longitud\n",
    "X_padded = pad_sequences(sequences, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Vocabulario total: {len(tokenizer.word_index):,} palabras únicas\")\n",
    "print(f\"Vocabulario usado: {VOCAB_SIZE:,} palabras\")\n",
    "print(f\"Forma de X_padded: {X_padded.shape}\")\n",
    "print(f\"\\nEjemplo de transformación:\")\n",
    "print(f\"Original: {X[0][:100]}...\")\n",
    "print(f\"Secuencia: {sequences[0][:20]}...\")\n",
    "print(f\"Padded: {X_padded[0][:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_section",
   "metadata": {},
   "source": [
    "### 3.4 División Train/Validation/Test\n",
    "\n",
    "- **Train**: 70% para entrenamiento\n",
    "- **Validation**: 15% para ajuste de hiperparámetros y early stopping\n",
    "- **Test**: 15% para evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIVISIÓN DE DATOS\n",
      "============================================================\n",
      "Train: 4,198 samples (70.0%)\n",
      "Validation: 897 samples (15.0%)\n",
      "Test: 900 samples (15.0%)\n",
      "\n",
      "Distribución en Train: Positivos=2097, Negativos=2101\n",
      "Distribución en Val: Positivos=448, Negativos=449\n",
      "Distribución en Test: Positivos=450, Negativos=450\n"
     ]
    }
   ],
   "source": [
    "# Primera división: Train+Val (85%) vs Test (15%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_padded, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Segunda división: Train (70%) vs Val (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=RANDOM_STATE, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIVISIÓN DE DATOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train: {len(X_train):,} samples ({len(X_train)/len(X_padded)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(X_val):,} samples ({len(X_val)/len(X_padded)*100:.1f}%)\")\n",
    "print(f\"Test: {len(X_test):,} samples ({len(X_test)/len(X_padded)*100:.1f}%)\")\n",
    "print(f\"\\nDistribución en Train: Positivos={np.sum(y_train==0)}, Negativos={np.sum(y_train==1)}\")\n",
    "print(f\"Distribución en Val: Positivos={np.sum(y_val==0)}, Negativos={np.sum(y_val==1)}\")\n",
    "print(f\"Distribución en Test: Positivos={np.sum(y_test==0)}, Negativos={np.sum(y_test==1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "word2vec_section",
   "metadata": {},
   "source": [
    "### 3.5 Entrenamiento de Word2Vec (Propósito Didáctico)\n",
    "\n",
    "#### ¿Por qué Word2Vec?\n",
    "\n",
    "Word2Vec es una técnica de **word embeddings** que convierte palabras en vectores densos. A diferencia de embeddings aleatorios (Keras por defecto), Word2Vec aprende representaciones semánticas:\n",
    "\n",
    "**Ventajas Didácticas:**\n",
    "- **Captura similitud semántica**: Palabras similares → vectores cercanos\n",
    "- **Relaciones contextuales**: \"good\" y \"great\" estarán cerca\n",
    "- **Visualizable**: Podemos explorar similitudes\n",
    "- **Pre-entrenado**: Los embeddings se entrenan ANTES de LSTM\n",
    "\n",
    "**Parámetros:**\n",
    "- **vector_size=128**: Dimensión (coincide con EMBEDDING_DIM)\n",
    "- **window=5**: Contexto de palabras vecinas\n",
    "- **min_count=2**: Palabras que aparecen ≥2 veces\n",
    "- **sg=1**: Skip-gram (mejor para datasets pequeños)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "word2vec_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos para Word2Vec...\n",
      "✓ Total de reviews: 5,995\n",
      "✓ Ejemplo de sentencia: ['sculpting', 'crean', 'use', 'this', 'product', 'and', 'find', 'that', 'when', 'run', 'out', 'notice', 'the', 'difference', 'the']...\n",
      "\n",
      "Entrenando Word2Vec...\n",
      "\n",
      "✓ Word2Vec entrenado\n",
      "✓ Vocabulario Word2Vec: 5,544 palabras\n",
      "✓ Modelo Word2Vec guardado en outputs/models/word2vec_beauty.model\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos para Word2Vec (necesita lista de listas de palabras)\n",
    "print(\"Preparando datos para Word2Vec...\")\n",
    "sentences = [text.split() for text in X]  # Convertir textos a listas de palabras\n",
    "\n",
    "print(f\"✓ Total de reviews: {len(sentences):,}\")\n",
    "print(f\"✓ Ejemplo de sentencia: {sentences[0][:15]}...\")\n",
    "\n",
    "# Entrenar Word2Vec\n",
    "print(\"\\nEntrenando Word2Vec...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=EMBEDDING_DIM,  # Debe coincidir con EMBEDDING_DIM\n",
    "    window=5,                    # Contexto de 5 palabras\n",
    "    min_count=2,                 # Palabras que aparecen al menos 2 veces\n",
    "    workers=4,                   # Procesamiento paralelo\n",
    "    sg=1,                        # Skip-gram (mejor para datasets pequeños)\n",
    "    epochs=10,                   # Número de épocas de entrenamiento\n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Word2Vec entrenado\")\n",
    "print(f\"✓ Vocabulario Word2Vec: {len(w2v_model.wv):,} palabras\")\n",
    "\n",
    "# Guardar modelo Word2Vec\n",
    "os.makedirs('Outputs/models', exist_ok=True)\n",
    "w2v_model.save('Outputs/models/word2vec_beauty.model')\n",
    "print(\"✓ Modelo Word2Vec guardado en outputs/models/word2vec_beauty.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "word2vec_explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPLORACIÓN DE WORD2VEC - SIMILITUDES SEMÁNTICAS\n",
      "============================================================\n",
      "\n",
      "'good' es similar a:\n",
      "  - great: 0.755\n",
      "  - low: 0.747\n",
      "  - bargain: 0.743\n",
      "  - suggested: 0.731\n",
      "  - reasonable: 0.729\n",
      "\n",
      "'bad' es similar a:\n",
      "  - funky: 0.702\n",
      "  - batch: 0.698\n",
      "  - news: 0.690\n",
      "  - cheep: 0.688\n",
      "  - negative: 0.681\n",
      "\n",
      "'love' es similar a:\n",
      "  - fantastic: 0.718\n",
      "  - awesome: 0.713\n",
      "  - amazing: 0.706\n",
      "  - starter: 0.699\n",
      "  - fun: 0.696\n",
      "\n",
      "'hate' es similar a:\n",
      "  - miss: 0.903\n",
      "  - shortvery: 0.893\n",
      "  - bummed: 0.888\n",
      "  - sparse: 0.884\n",
      "  - reordered: 0.884\n",
      "\n",
      "'quality' es similar a:\n",
      "  - design: 0.694\n",
      "  - stitching: 0.674\n",
      "  - theory: 0.671\n",
      "  - poor: 0.668\n",
      "  - bowl: 0.664\n",
      "\n",
      "'price' es similar a:\n",
      "  - reasonable: 0.781\n",
      "  - deal: 0.766\n",
      "  - cost: 0.733\n",
      "  - value: 0.730\n",
      "  - tag: 0.730\n",
      "\n",
      "'product' es similar a:\n",
      "  - satisfied: 0.726\n",
      "  - expectations: 0.714\n",
      "  - item: 0.708\n",
      "  - reports: 0.706\n",
      "  - reviewing: 0.703\n",
      "\n",
      "'recommend' es similar a:\n",
      "  - anyone: 0.728\n",
      "  - highly: 0.661\n",
      "  - reccomend: 0.658\n",
      "  - def: 0.641\n",
      "  - dumb: 0.641\n"
     ]
    }
   ],
   "source": [
    "# Explorar similitudes (Propósito Didáctico)\n",
    "print(\"=\"*60)\n",
    "print(\"EXPLORACIÓN DE WORD2VEC - SIMILITUDES SEMÁNTICAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Palabras de ejemplo relacionadas con sentiment\n",
    "test_words = ['good', 'bad', 'love', 'hate', 'quality', 'price', 'product', 'recommend']\n",
    "\n",
    "for word in test_words:\n",
    "    if word in w2v_model.wv:\n",
    "        similar = w2v_model.wv.most_similar(word, topn=5)\n",
    "        print(f\"\\n'{word}' es similar a:\")\n",
    "        for sim_word, score in similar:\n",
    "            print(f\"  - {sim_word}: {score:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n'{word}' no está en el vocabulario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "embedding_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creando matriz de embeddings desde Word2Vec...\n",
      "\n",
      "✓ Matriz de embeddings creada: (5000, 128)\n",
      "✓ Palabras encontradas en Word2Vec: 4,998/5,000 (100.0%)\n",
      "✓ Palabras sin embedding (inicializadas a cero): 2\n"
     ]
    }
   ],
   "source": [
    "# Crear matriz de embeddings desde Word2Vec\n",
    "print(\"\\nCreando matriz de embeddings desde Word2Vec...\")\n",
    "\n",
    "# Inicializar matriz con ceros\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# Llenar matriz con vectores de Word2Vec\n",
    "words_found = 0\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if idx < VOCAB_SIZE:  # Solo palabras en nuestro vocabulario\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[idx] = w2v_model.wv[word]\n",
    "            words_found += 1\n",
    "\n",
    "coverage = (words_found / VOCAB_SIZE) * 100\n",
    "print(f\"\\n✓ Matriz de embeddings creada: {embedding_matrix.shape}\")\n",
    "print(f\"✓ Palabras encontradas en Word2Vec: {words_found:,}/{VOCAB_SIZE:,} ({coverage:.1f}%)\")\n",
    "print(f\"✓ Palabras sin embedding (inicializadas a cero): {VOCAB_SIZE - words_found:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gru_section",
   "metadata": {},
   "source": [
    "### 3.6 Modelo 1: GRU\n",
    "\n",
    "**Arquitectura:**\n",
    "1. **Embedding Layer**: Usa embeddings de Word2Vec (trainable=False)\n",
    "2. **SpatialDropout1D**: Regularización para embeddings (20%)\n",
    "3. **GRU**: 64 unidades, captura dependencias temporales\n",
    "4. **Dropout**: Regularización (50%)\n",
    "5. **Dense**: Capa de salida con sigmoid\n",
    "\n",
    "**Justificación de Parámetros:**\n",
    "- **GRU units=64**: Balance entre capacidad y overfitting para ~4K samples\n",
    "- **Dropout=0.5**: Regularización fuerte para evitar overfitting\n",
    "- **trainable=False**: Mantener embeddings Word2Vec fijos (didáctico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gru_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/nlp-dl-stable/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "✓ Modelo GRU creado con embeddings de Word2Vec\n",
      "✓ Embeddings NO entrenables (trainable=False) - usamos Word2Vec tal cual\n"
     ]
    }
   ],
   "source": [
    "# Construir modelo GRU con Word2Vec embeddings\n",
    "def build_gru_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        # Embedding layer con pesos de Word2Vec\n",
    "        Embedding(\n",
    "            VOCAB_SIZE, \n",
    "            EMBEDDING_DIM, \n",
    "            weights=[embedding_matrix],  # Usar embeddings de Word2Vec\n",
    "            input_length=MAX_LENGTH,\n",
    "            trainable=False  # No entrenar embeddings (usar Word2Vec tal cual)\n",
    "        ),\n",
    "        SpatialDropout1D(0.2),\n",
    "        GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = build_gru_model(embedding_matrix)\n",
    "print(gru_model.summary())\n",
    "\n",
    "print(\"\\n✓ Modelo GRU creado con embeddings de Word2Vec\")\n",
    "print(\"✓ Embeddings NO entrenables (trainable=False) - usamos Word2Vec tal cual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gru_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo GRU...\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5001 - loss: 0.6923 - precision: 0.4973 - recall: 0.7118\n",
      "Epoch 1: val_accuracy improved from None to 0.50725, saving model to outputs/models/gru_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.5031 - loss: 0.6921 - precision: 0.5030 - recall: 0.5926 - val_accuracy: 0.5072 - val_loss: 0.6920 - val_precision: 0.5040 - val_recall: 0.9733 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4968 - loss: 0.6919 - precision: 0.5001 - recall: 0.7820\n",
      "Epoch 2: val_accuracy did not improve from 0.50725\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5026 - loss: 0.6910 - precision: 0.5022 - recall: 0.7068 - val_accuracy: 0.5006 - val_loss: 0.6916 - val_precision: 1.0000 - val_recall: 0.0022 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5129 - loss: 0.6903 - precision: 0.4932 - recall: 0.2689\n",
      "Epoch 3: val_accuracy improved from 0.50725 to 0.51059, saving model to outputs/models/gru_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5088 - loss: 0.6904 - precision: 0.5102 - recall: 0.4622 - val_accuracy: 0.5106 - val_loss: 0.6920 - val_precision: 0.5058 - val_recall: 0.9777 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5051 - loss: 0.6911 - precision: 0.4958 - recall: 0.7019\n",
      "Epoch 4: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5124 - loss: 0.6893 - precision: 0.5111 - recall: 0.5907 - val_accuracy: 0.5084 - val_loss: 0.6949 - val_precision: 0.5045 - val_recall: 0.9911 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4955 - loss: 0.6886 - precision: 0.4917 - recall: 0.6682\n",
      "Epoch 5: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.4993 - loss: 0.6901 - precision: 0.4998 - recall: 0.6168 - val_accuracy: 0.5050 - val_loss: 0.6914 - val_precision: 0.5029 - val_recall: 0.9733 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5087 - loss: 0.6883 - precision: 0.4733 - recall: 0.2530\n",
      "Epoch 6: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5155 - loss: 0.6878 - precision: 0.5202 - recall: 0.4112 - val_accuracy: 0.5061 - val_loss: 0.6933 - val_precision: 0.5034 - val_recall: 0.9755 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5011 - loss: 0.6891 - precision: 0.5006 - recall: 0.7300\n",
      "Epoch 7: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - accuracy: 0.5010 - loss: 0.6886 - precision: 0.5012 - recall: 0.6007 - val_accuracy: 0.5072 - val_loss: 0.6923 - val_precision: 0.5040 - val_recall: 0.9755 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5019 - loss: 0.6873 - precision: 0.4991 - recall: 0.6479\n",
      "Epoch 8: val_accuracy did not improve from 0.51059\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.4988 - loss: 0.6879 - precision: 0.4994 - recall: 0.5578 - val_accuracy: 0.5084 - val_loss: 0.6927 - val_precision: 0.5046 - val_recall: 0.9800 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5268 - loss: 0.6858 - precision: 0.5216 - recall: 0.9388\n",
      "Epoch 9: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5205 - loss: 0.6856 - precision: 0.5131 - recall: 0.8177 - val_accuracy: 0.4994 - val_loss: 0.6928 - val_precision: 0.5000 - val_recall: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5097 - loss: 0.6846 - precision: 0.5159 - recall: 0.4212\n",
      "Epoch 10: val_accuracy did not improve from 0.51059\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.5143 - loss: 0.6854 - precision: 0.5178 - recall: 0.4284 - val_accuracy: 0.5084 - val_loss: 0.6939 - val_precision: 0.5046 - val_recall: 0.9755 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "✓ Entrenamiento GRU completado\n"
     ]
    }
   ],
   "source": [
    "# Callbacks para GRU\n",
    "gru_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'outputs/models/gru_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Entrenar GRU\n",
    "print(\"Entrenando modelo GRU...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "gru_history = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=gru_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Entrenamiento GRU completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm_section",
   "metadata": {},
   "source": [
    "### 3.7 Modelo 2: LSTM con Word2Vec\n",
    "\n",
    "**Arquitectura:**\n",
    "Similar a GRU pero con LSTM (más parámetros)\n",
    "\n",
    "**Ventajas de LSTM:**\n",
    "- **Más parámetros**: Mayor capacidad de aprendizaje\n",
    "- **Mejor para secuencias largas**: Captura dependencias complejas\n",
    "- **Estándar de la industria**: LSTM es el modelo más usado\n",
    "- **Maneja negaciones**: Mejor contexto para sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lstm_model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> (2.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640,000\u001b[0m (2.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "✓ Modelo LSTM creado con embeddings de Word2Vec\n",
      "✓ Embeddings NO entrenables (trainable=False) - usamos Word2Vec tal cual\n"
     ]
    }
   ],
   "source": [
    "# Construir modelo LSTM con Word2Vec embeddings\n",
    "def build_lstm_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        # Embedding layer con pesos de Word2Vec\n",
    "        Embedding(\n",
    "            VOCAB_SIZE, \n",
    "            EMBEDDING_DIM, \n",
    "            weights=[embedding_matrix],  # Usar embeddings de Word2Vec\n",
    "            input_length=MAX_LENGTH,\n",
    "            trainable=False  # No entrenar embeddings (usar Word2Vec tal cual)\n",
    "        ),\n",
    "        SpatialDropout1D(0.2),\n",
    "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_model = build_lstm_model(embedding_matrix)\n",
    "print(lstm_model.summary())\n",
    "\n",
    "print(\"\\n✓ Modelo LSTM creado con embeddings de Word2Vec\")\n",
    "print(\"✓ Embeddings NO entrenables (trainable=False) - usamos Word2Vec tal cual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lstm_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo LSTM...\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4896 - loss: 0.6931 - precision_1: 0.4843 - recall_1: 0.5229\n",
      "Epoch 1: val_accuracy improved from None to 0.49944, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.4895 - loss: 0.6930 - precision_1: 0.4892 - recall_1: 0.4517 - val_accuracy: 0.4994 - val_loss: 0.6939 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5004 - loss: 0.6910 - precision_1: 0.4803 - recall_1: 0.5422\n",
      "Epoch 2: val_accuracy improved from 0.49944 to 0.50167, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.5002 - loss: 0.6915 - precision_1: 0.5005 - recall_1: 0.6816 - val_accuracy: 0.5017 - val_loss: 0.6924 - val_precision_1: 1.0000 - val_recall_1: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4991 - loss: 0.6903 - precision_1: 0.5013 - recall_1: 0.6287\n",
      "Epoch 3: val_accuracy improved from 0.50167 to 0.50725, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.4995 - loss: 0.6914 - precision_1: 0.5000 - recall_1: 0.7649 - val_accuracy: 0.5072 - val_loss: 0.6922 - val_precision_1: 0.5040 - val_recall_1: 0.9710 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4994 - loss: 0.6904 - precision_1: 0.4840 - recall_1: 0.4002\n",
      "Epoch 4: val_accuracy improved from 0.50725 to 0.50948, saving model to outputs/models/lstm_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.4983 - loss: 0.6911 - precision_1: 0.4990 - recall_1: 0.6235 - val_accuracy: 0.5095 - val_loss: 0.6925 - val_precision_1: 0.5052 - val_recall_1: 0.9666 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5123 - loss: 0.6892 - precision_1: 0.5114 - recall_1: 0.6474\n",
      "Epoch 5: val_accuracy did not improve from 0.50948\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.5067 - loss: 0.6907 - precision_1: 0.5049 - recall_1: 0.7430 - val_accuracy: 0.5039 - val_loss: 0.6927 - val_precision_1: 0.6000 - val_recall_1: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5088 - loss: 0.6886 - precision_1: 0.5216 - recall_1: 0.4382\n",
      "Epoch 6: val_accuracy did not improve from 0.50948\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.5141 - loss: 0.6893 - precision_1: 0.5132 - recall_1: 0.5650 - val_accuracy: 0.5017 - val_loss: 0.6929 - val_precision_1: 0.5714 - val_recall_1: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5074 - loss: 0.6885 - precision_1: 0.5417 - recall_1: 0.1879\n",
      "Epoch 7: val_accuracy did not improve from 0.50948\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.5021 - loss: 0.6890 - precision_1: 0.5048 - recall_1: 0.2732 - val_accuracy: 0.5072 - val_loss: 0.6931 - val_precision_1: 0.5040 - val_recall_1: 0.9733 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4976 - loss: 0.6876 - precision_1: 0.4798 - recall_1: 0.4176\n",
      "Epoch 8: val_accuracy did not improve from 0.50948\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.5057 - loss: 0.6890 - precision_1: 0.5050 - recall_1: 0.6311 - val_accuracy: 0.5061 - val_loss: 0.6935 - val_precision_1: 0.5035 - val_recall_1: 0.9733 - learning_rate: 5.0000e-04\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "✓ Entrenamiento LSTM completado\n"
     ]
    }
   ],
   "source": [
    "# Callbacks para LSTM\n",
    "lstm_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'outputs/models/lstm_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Entrenar LSTM\n",
    "print(\"Entrenando modelo LSTM...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=lstm_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Entrenamiento LSTM completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "### 3.8 Evaluación de Modelos en Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gru_eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUACIÓN GRU EN TEST SET\n",
      "============================================================\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      "Accuracy:  0.5133\n",
      "Precision: 0.5070\n",
      "Recall:    0.9711\n",
      "F1-Score:  0.6662\n",
      "ROC-AUC:   0.5338\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.66      0.06      0.10       450\n",
      "    Negative       0.51      0.97      0.67       450\n",
      "\n",
      "    accuracy                           0.51       900\n",
      "   macro avg       0.58      0.51      0.38       900\n",
      "weighted avg       0.58      0.51      0.38       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación GRU\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUACIÓN GRU EN TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_gru_proba = gru_model.predict(X_test)\n",
    "y_pred_gru = (y_pred_gru_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Métricas\n",
    "gru_accuracy = accuracy_score(y_test, y_pred_gru)\n",
    "gru_precision = precision_score(y_test, y_pred_gru)\n",
    "gru_recall = recall_score(y_test, y_pred_gru)\n",
    "gru_f1 = f1_score(y_test, y_pred_gru)\n",
    "gru_auc = roc_auc_score(y_test, y_pred_gru_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {gru_accuracy:.4f}\")\n",
    "print(f\"Precision: {gru_precision:.4f}\")\n",
    "print(f\"Recall:    {gru_recall:.4f}\")\n",
    "print(f\"F1-Score:  {gru_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {gru_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gru, target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lstm_eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUACIÓN LSTM EN TEST SET\n",
      "============================================================\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\n",
      "Accuracy:  0.5211\n",
      "Precision: 0.5111\n",
      "Recall:    0.9689\n",
      "F1-Score:  0.6692\n",
      "ROC-AUC:   0.5739\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.70      0.07      0.13       450\n",
      "    Negative       0.51      0.97      0.67       450\n",
      "\n",
      "    accuracy                           0.52       900\n",
      "   macro avg       0.61      0.52      0.40       900\n",
      "weighted avg       0.61      0.52      0.40       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación LSTM\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUACIÓN LSTM EN TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lstm_proba = lstm_model.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Métricas\n",
    "lstm_accuracy = accuracy_score(y_test, y_pred_lstm)\n",
    "lstm_precision = precision_score(y_test, y_pred_lstm)\n",
    "lstm_recall = recall_score(y_test, y_pred_lstm)\n",
    "lstm_f1 = f1_score(y_test, y_pred_lstm)\n",
    "lstm_auc = roc_auc_score(y_test, y_pred_lstm_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {lstm_accuracy:.4f}\")\n",
    "print(f\"Precision: {lstm_precision:.4f}\")\n",
    "print(f\"Recall:    {lstm_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lstm_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {lstm_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "### 3.9 Comparación Final: GRU vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comparison_table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARACIÓN GRU vs LSTM + Word2Vec\n",
      "============================================================\n",
      "          Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "            GRU  0.513333   0.506961 0.971111  0.666159 0.533780\n",
      "LSTM + Word2Vec  0.521111   0.511137 0.968889  0.669225 0.573904\n",
      "\n",
      "✓ Mejor modelo: LSTM + Word2Vec (F1-Score: 0.6692)\n",
      "✓ Resultados guardados en outputs/results_deep_learning.csv\n"
     ]
    }
   ],
   "source": [
    "# Tabla comparativa\n",
    "results_dl = pd.DataFrame({\n",
    "    'Model': ['GRU', 'LSTM + Word2Vec'],\n",
    "    'Accuracy': [gru_accuracy, lstm_accuracy],\n",
    "    'Precision': [gru_precision, lstm_precision],\n",
    "    'Recall': [gru_recall, lstm_recall],\n",
    "    'F1-Score': [gru_f1, lstm_f1],\n",
    "    'ROC-AUC': [gru_auc, lstm_auc]\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARACIÓN GRU vs LSTM + Word2Vec\")\n",
    "print(\"=\"*60)\n",
    "print(results_dl.to_string(index=False))\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_idx = results_dl['F1-Score'].idxmax()\n",
    "best_model_name = results_dl.loc[best_model_idx, 'Model']\n",
    "best_f1 = results_dl.loc[best_model_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\n✓ Mejor modelo: {best_model_name} (F1-Score: {best_f1:.4f})\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_dl.to_csv('outputs/results_deep_learning.csv', index=False)\n",
    "print(\"✓ Resultados guardados en outputs/results_deep_learning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comparison_viz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización comparativa\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "gru_scores = [gru_accuracy, gru_precision, gru_recall, gru_f1, gru_auc]\n",
    "lstm_scores = [lstm_accuracy, lstm_precision, lstm_recall, lstm_f1, lstm_auc]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, gru_scores, width, label='GRU', color='seagreen')\n",
    "bars2 = ax.bar(x + width/2, lstm_scores, width, label='LSTM + Word2Vec', color='steelblue')\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Métricas')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparación GRU vs LSTM + Word2Vec - Deep Learning')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions_section",
   "metadata": {},
   "source": [
    "### 3.10 Conclusiones\n",
    "\n",
    "#### Sobre Word2Vec:\n",
    "- **Ventajas**: Captura relaciones semánticas, palabras similares tienen vectores cercanos\n",
    "- **Limitaciones**: Requiere corpus grande, palabras OOV se inicializan a cero\n",
    "\n",
    "#### Comparación GRU vs LSTM:\n",
    "- **GRU**: Más eficiente, menos parámetros, entrena más rápido, menos overfitting\n",
    "- **LSTM**: Más parámetros, mejor para secuencias largas, estándar de la industria\n",
    "\n",
    "#### Recomendaciones:\n",
    "1. **Para datasets pequeños-medianos (~6K)**: GRU suele ser mejor opción\n",
    "2. **Para reviews largas**: LSTM captura mejor las dependencias\n",
    "3. **Para producción**: Considerar trade-off rendimiento vs velocidad\n",
    "4. **Word2Vec**: Útil didácticamente, pero considerar embeddings pre-entrenados más grandes (GloVe, FastText, BERT) en producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "save_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando modelos...\n",
      "✓ Mejor modelo (LSTM) guardado en outputs/models/best_dl_model.h5\n",
      "✓ Tokenizer guardado en outputs/models/tokenizer.pkl\n",
      "✓ Embedding matrix guardada en outputs/models/embedding_matrix.npy\n",
      "\n",
      "============================================================\n",
      "NOTEBOOK 3b COMPLETADO\n",
      "============================================================\n",
      "✓ Modelos GRU y LSTM + Word2Vec entrenados\n",
      "✓ Mejor modelo: LSTM + Word2Vec (F1-Score: 0.6692)\n",
      "✓ Todos los resultados guardados en outputs/\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelos finales\n",
    "print(\"Guardando modelos...\")\n",
    "\n",
    "# Guardar el mejor modelo según F1-Score\n",
    "if best_model_name == 'GRU':\n",
    "    gru_model.save('outputs/models/best_dl_model.h5')\n",
    "    print(f\"✓ Mejor modelo (GRU) guardado en outputs/models/best_dl_model.h5\")\n",
    "else:\n",
    "    lstm_model.save('outputs/models/best_dl_model.h5')\n",
    "    print(f\"✓ Mejor modelo (LSTM) guardado en outputs/models/best_dl_model.h5\")\n",
    "\n",
    "# Guardar tokenizer\n",
    "with open('outputs/models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"✓ Tokenizer guardado en outputs/models/tokenizer.pkl\")\n",
    "\n",
    "# Guardar embedding matrix\n",
    "np.save('outputs/models/embedding_matrix.npy', embedding_matrix)\n",
    "print(\"✓ Embedding matrix guardada en outputs/models/embedding_matrix.npy\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK 3b COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Modelos GRU y LSTM + Word2Vec entrenados\")\n",
    "print(f\"✓ Mejor modelo: {best_model_name} (F1-Score: {best_f1:.4f})\")\n",
    "print(f\"✓ Todos los resultados guardados en outputs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP DL (Python 3.11)",
   "language": "python",
   "name": "nlp-dl-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
